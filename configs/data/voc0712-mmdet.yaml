debug:
  view_train_augmentation:
    resize_to: [256, 256] # resize so class text is displayed.
  network_summary:
    input_shape: [3, 224, 224]
dataset:
  MODE: "mmdetection"
  NAME: "CIFAR10"
  # list of parameters used when using `data.dataset.torchvision_dataset` to load `torchvision.datasets`
  dataset_base_cfg:
    root: "./cifar10"
  dataset_subset_cfg:
    trn:
      download: True
      train: True
    val:
      train: False
  initial_transform:
    name: "TupleToClassificationData"

# default data augmentation for CIFAR-10 is from https://github.com/kuangliu/pytorch-cifar/blob/master/main.py#L30
transform:
  [
    [
      "trn",
      [
        {
          "name": "TorchTransforms",
          "args":
            { "NAME": "RandomCrop", "ARGS": { "size": 32, "padding": 4 } },
        },
        {
          "name": "TorchTransforms",
          "args": { "NAME": "RandomHorizontalFlip" },
        },
      ],
    ],
    [
      "trn,val",
      [
        { "name": "ToTensor", "args": {} },
        {
          "name": "Normalize",
          "args":
            {
              "mean": "{const.normalization_mean}",
              "std": "{const.normalization_std}",
            },
        },
      ],
    ],
  ]
# other useful configs.
const:
  task: "image classification"
  normalization_mean: [0.4914, 0.4822, 0.4465]
  normalization_std: [0.2023, 0.1994, 0.2010]
  num_classes: 10
  label_map:
    - "airplane"
    - "automobile"
    - "bird"
    - "cat"
    - "deer"
    - "dog"
    - "frog"
    - "horse"
    - "ship"
    - "truck"

data:
  samples_per_gpu: 2
  test:
    ann_file: data/VOCdevkit/VOC2007/ImageSets/Main/test.txt
    img_prefix: data/VOCdevkit/VOC2007/
    pipeline:
    - type: LoadImageFromFile
    - flip: false
      img_scale:
      - 1000
      - 600
      transforms:
      - keep_ratio: true
        type: Resize
      - type: RandomFlip
      - mean:
        - 123.675
        - 116.28
        - 103.53
        std:
        - 58.395
        - 57.12
        - 57.375
        to_rgb: true
        type: Normalize
      - size_divisor: 32
        type: Pad
      - keys:
        - img
        type: ImageToTensor
      - keys:
        - img
        type: Collect
      type: MultiScaleFlipAug
    type: VOCDataset
  train:
    dataset:
      ann_file:
      - data/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt
      - data/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt
      img_prefix:
      - data/VOCdevkit/VOC2007/
      - data/VOCdevkit/VOC2012/
      pipeline:
      - type: LoadImageFromFile
      - type: LoadAnnotations
        with_bbox: true
      - img_scale:
        - 1000
        - 600
        keep_ratio: true
        type: Resize
      - flip_ratio: 0.5
        type: RandomFlip
      - mean:
        - 123.675
        - 116.28
        - 103.53
        std:
        - 58.395
        - 57.12
        - 57.375
        to_rgb: true
        type: Normalize
      - size_divisor: 32
        type: Pad
      - type: DefaultFormatBundle
      - keys:
        - img
        - gt_bboxes
        - gt_labels
        type: Collect
      type: VOCDataset
    times: 3
    type: RepeatDataset
  val:
    ann_file: data/VOCdevkit/VOC2007/ImageSets/Main/test.txt
    img_prefix: data/VOCdevkit/VOC2007/
    pipeline:
    - type: LoadImageFromFile
    - flip: false
      img_scale:
      - 1000
      - 600
      transforms:
      - keep_ratio: true
        type: Resize
      - type: RandomFlip
      - mean:
        - 123.675
        - 116.28
        - 103.53
        std:
        - 58.395
        - 57.12
        - 57.375
        to_rgb: true
        type: Normalize
      - size_divisor: 32
        type: Pad
      - keys:
        - img
        type: ImageToTensor
      - keys:
        - img
        type: Collect
      type: MultiScaleFlipAug
    type: VOCDataset
  workers_per_gpu: 2

name: "CowPrediction"

dataset:
  trn_size: 9000
  val_size: 1000

transform:
  [
    [
      "trn",
      [
        {
          "name": "TorchTransforms",
          "args": { "NAME": "RandomHorizontalFlip" },
        },
        { "name": "TorchTransforms", "args": { "NAME": "RandomVerticalFlip" } },
        {
          "name": "TorchTransforms",
          "args": { "NAME": "RandomRotation", "ARGS": { "degrees": [0, 360] } },
        },
      ],
    ],
    ["trn,val", [{ "name": "ClassificationLabelEncoder" }]],

    [
      "trn,val,pred",
      [
        { "name": "Resize", "args": { "size": [224, 224] } },
        { "name": "ToTensor", "args": {} },
        {
          "name": "Normalize",
          "args":
            {
              "mean": [0.25252014, 0.12918881, 0.12411932],
              "std": [0.24537923, 0.17195621, 0.17269008],
            },
        },
      ],
    ],
  ]

model:
  backbone:
    TYPE: "timm"
    ID: "resnet18"
    cfg:
      pretrained: True
    out_features: 512
  modules:
    classifier:
      name: "ClassificationHead"
      input: "output"
      args:
        reduction: "gap"
        in_features: 512
        dropout: 0.2
        num_classes: 5
        return_logits: True # return logits instead of softmax probability.
    loss_fn:
      name: "CrossEntropyLoss"

dataloader:
  base_dataloader:
    num_workers: 4  # 4 -> ~43s, 8 -> ~48s

training:
  ID: "ClassificationTrainer"

  epochs: 200
  lr: 0.1
  batch_size: 64
  optimizer: "sgd"
  optimizer_cfg:
    momentum: 0.9
    weight_decay: 0.0005
  lr_scheduler: "cosine"
  lr_scheduler_cfg: {}
  lr_warmup:
    multiplier: 1
    total_epoch: 5
validation:
  batch_size: 64
  metrics:

debug:
  network_summary:
    input_shape: [3, 224, 224]

# other useful configs.
wandb:
  project: "cow_grade_prediction_challenge_2022"

const:
  task: "image classification"
  normalization_mean: [0.25252014, 0.12918881, 0.12411932]
  normalization_std: [0.24537923, 0.17195621, 0.17269008]

  label_map:
    - "1++"
    - "1+"
    - "1"
    - "2"
    - "3"
